{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2StPehwLMat"
   },
   "source": [
    "# Tobig's 19기 2주차 Optimization 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIX8PqcLMaw"
   },
   "source": [
    "# Gradient Descent 구현하기\n",
    "\n",
    "### 1)\"...\"표시되어 있는 빈 칸을 채워주세요\n",
    "### 2)강의내용과 코드에 대해 공부한 내용을 마크마운 또는 주석으로 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6DNHHXfLMax"
   },
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EP3O4xptLMay"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oByQ9wXHLMay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOR3hWGLMaz"
   },
   "source": [
    "## Train Test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IySSjlizLMaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "075EQI1bLMa0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "O8Ht5u8kLMa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYmxND_xLMa2"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "experience와 salary의 단위, 평균, 분산이 크게 차이나므로 scaler를 사용해 단위를 맞춰줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UI0Xy0gHLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD7L7RwZLMa3"
   },
   "source": [
    "이때 scaler는 X_train에 fit 해주시고, fit한 scaler를 X_test에 적용시켜줍니다.  \n",
    "똑같이 X_test에다 fit하면 안돼요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xBsUSCGGLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m9sP3nzlLMa4"
   },
   "outputs": [],
   "source": [
    "# parameter 개수\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qz7xz9dbLMa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13639807, 0.47924837, 0.46317347])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 parameter들을 임의로 설정해줍니다.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "random_parameters = parameters.copy()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QINz-EAKLMa4"
   },
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebook은 LaTeX 문법으로 수식 입력을 지원하고 있습니다.  \n",
    "LaTeX문법으로 아래의 수식을 완성해주세요  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2DsTfXuLMa5"
   },
   "source": [
    "## Dot product\n",
    "## $z = X_i \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2y05lS6xLMa5"
   },
   "outputs": [],
   "source": [
    "def dot_product(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)):\n",
    "        z += X[i] * parameters[i]\n",
    "    \n",
    "        \n",
    "    # dot product는 두 벡터의 내적을 계산하는 연산임,\n",
    "    # 내적되는 두 벡터는 feature 벡터와 parameter 벡터임. \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGPEhtOLMa5"
   },
   "source": [
    "## Logistic Function\n",
    "\n",
    "## $p = \\frac{1}{1 + e^{-\\mathbf{X_i} \\cdot \\mathbf{\\theta}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2awM57u5LMa5"
   },
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = dot_product(X, parameters)\n",
    "    p = 1/(1+ np.exp(-z))\n",
    "    # logistic function을 이용해서 범위가 제한되지 않은 X값들을 \n",
    "    # 정의한 시그모이드 함수를 이용해 y값을 [0,1]로 제한한 것\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WVaZEwrdLMa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6736941859991545"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6cXHl8bLMa6"
   },
   "source": [
    "## Object function\n",
    "\n",
    "Object Function : 목적함수는 Gradient Descent를 통해 최적화 하고자 하는 함수입니다.  \n",
    "<br>\n",
    "선형 회귀의 목적함수\n",
    "## $l(\\theta) = \\frac{1}{2}\\Sigma(y_i - \\theta^{T}X_i)^2$  \n",
    "참고) $\\hat{y_i} = \\theta^{T}X_i$\n",
    "  \n",
    "로지스틱 회귀의 목적함수를 작성해주세요  \n",
    "(선형 회귀의 목적함수처럼 강의에 나온대로 작성해주세요. 평균을 고려하는 것은 뒤에 코드에서 수행합니다)\n",
    "## $l(p) = -\\sum_{i=1}^{m} \\left( y_i \\log({p}(X_i)) + (1 - y_i) \\log(1 - {p}(X_i)) \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FnGRAur3LMa6"
   },
   "outputs": [],
   "source": [
    "def minus_log_cross_entropy_i(X, y, parameters):\n",
    "    p = logistic(X, parameters) # Y_Pred라고 말하는 계산된 확률값\n",
    "    loss = - y* np.log(p) + (1 - y) * np.log(1 - p)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# 로지스틱 회귀의 확률값과 실제 타겟값의 오차를 계산하는 함수임. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "C922eXYyLMa6"
   },
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    # theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    y_hat = dot_product(X, parameters)\n",
    "    loss = np.power(y-y_hat,2) / 2\n",
    "    return loss\n",
    "\n",
    "# 평균을 고려하는 것은 이후에 한다고 했으니 오차의 제곱까지만 구현\n",
    "# y_hat을 구현하기 위해 theta라는 베타변수 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0j-MhGkyLMa6"
   },
   "outputs": [],
   "source": [
    "def batch_loss(X_set, y_set, parameters, loss_function, n): #n:현재 배치의 데이터 수\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += loss_function(X,y,parameters)\n",
    "    \n",
    "    loss /= n #loss 평균값으로 계산\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uSkPS5olLMa7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7137898427701908"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss(X_test, y_test, parameters, minus_log_cross_entropy_i, len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACLi9vCyLMa7"
   },
   "source": [
    "## Gradient\n",
    "위의 선형회귀의 목적함수 $l(\\theta)$와 로지스틱회귀의 목적함수 $l(p)$의 gradient를 작성해주세요  \n",
    "(위의 목적함수를 참고해서 작성해주세요 = 평균을 고려하는 것은 뒤에 코드에서 수행합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caMA-f00LMa7"
   },
   "source": [
    "## ${\\partial\\over{\\partial \\theta_j}}l(\\theta)= - \\sum_{i=1}^{m}(y_i - {\\theta}^{T}X_i)X_{ij} $\n",
    "\n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)= - \\sum_{i=1}^{m} (y_i - p_i)X_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "apZ0Miz5LMa7"
   },
   "outputs": [],
   "source": [
    "def get_gradient_ij(X, y, parameters, j, model):\n",
    "    if model == 'linear':\n",
    "        y_hat = dot_product(X, parameters) # 선형회귀 예측값\n",
    "        gradient = -(y-y_hat) * X[j]\n",
    "            # 선형회귀의 gradient. 이 코드는 모델이 linera일 때 gradient 계산함\n",
    "            # 선형회귀의 손실함수 = MSE \n",
    "    else:\n",
    "        p = logistic(X, parameters) \n",
    "        gradient = -(y-p)*X[j]\n",
    "            # 로지스틱 회귀의 gradient \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XXBe6q8gLMa7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10807688420964214"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij(X_train.iloc[0,:], y_train.iloc[0], parameters, 1, 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTfzKh_nLMa7"
   },
   "source": [
    "## Batch Gradient\n",
    "하나의 배치 (X_set, y_set)에 대해 기울기를 구하는 코드를 작성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Qby2_X1vLMa7"
   },
   "outputs": [],
   "source": [
    "def batch_gradient(X_set, y_set, parameters, model):\n",
    "    gradients = [0 for _ in range(len(parameters))]\n",
    "    \n",
    "    for i in range(len(X_set)):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij(X, y, parameters, j, model)\n",
    "             \n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rHxBS5RnLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37.00739539469123, 9.187667861005378, 40.729345378984014]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients1 = batch_gradient(X_train, y_train, parameters, 'logistic')\n",
    "gradients1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnlDboALMa8"
   },
   "source": [
    "## mini-batch\n",
    "인덱스로 미니 배치 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LgnfT6eHLMa8"
   },
   "outputs": [],
   "source": [
    "def batch_idx(X_train, batch_size):\n",
    "    N = len(X_train)\n",
    "    nb = (N // batch_size)+1 #number of batch\n",
    "    idx = np.array([i for i in range(N)])\n",
    "    idx_list = [idx[i*batch_size:(i+1)*batch_size] for i in range(nb) if len(idx[i*batch_size:(i+1)*batch_size]) != 0]\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S9fk1UTLMa8"
   },
   "source": [
    "batch_idx 함수에 대한 설명을 batch_size와 함께 간략하게 작성해주세요  \n",
    "### 설명: \n",
    "- X_train과 batch_size를 인자로 받아서 미니배치를 생성함\n",
    "- 먼저 입력 데이터의 개수 'N'을 구한다\n",
    "- 한개의 미니배치에 포함될 개수인 batch_size를 사용하여 전체 데이터 개수를 n으로 나눔. \n",
    "- 추가적인 미니배치가 필요한 경우 이를 nb에 저장.\n",
    "- 인덱스를 나타내는 배열 idx를 0부터 n-1까지 생성\n",
    "- idx배열을 nb개수만큼 미니 배치로 나눠서 각 미니 배치에 해당하는 인덱스 리스트 저장, \n",
    "- idx_list 반환. \n",
    "- 이후 gradient descent에서 idex_list를 사용하여 각 미니배치에 해당하는 데이터만 선택하여 학습 가능. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pMuZbkQLMa8"
   },
   "source": [
    "## Update Parameters\n",
    "기울기를 갱신하는 코드를 작성해주세요  \n",
    "(loss와 마찬가지로 기울기를 갱신할 때 배치 사이즈를 고려해 평균으로 갱신해주세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "loeL51rPLMa8"
   },
   "outputs": [],
   "source": [
    "def step(parameters, gradients, learning_rate, n): #n:현재 배치의 데이터 수\n",
    "    for i in range(len(parameters)):\n",
    "        gradients[i] *= learning_rate/n\n",
    "    \n",
    "    \n",
    "    parameters -= gradients \n",
    "    # 파라미터를 업데이트 한다\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NLB2dUVTLMa8",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13393091, 0.47863586, 0.46045818])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(parameters, gradients1, 0.01, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX8RJFd_LMa9"
   },
   "source": [
    "## Gradient Descent\n",
    "위에서 작성한 함수들을 조합해서 경사하강법 함수를 완성해주세요\n",
    "\n",
    "- learning_rate: 학습률  \n",
    "- tolerance: Step이 너무 작아서 더 이상의 학습이 무의미할 때 학습을 멈추는 조건  \n",
    "- batch: 기울기를 1번 갱신할 때 사용하는 데이터셋  \n",
    "- epoch: 전체 데이터셋을 이용해 학습한 횟수 \n",
    "- num_epoch: 학습 알고리즘에서 지정한 총 epoch의 수. 학습을 몇 번의 epoch까지 수행할지 결정하는 값\n",
    "<br>\n",
    "\n",
    "- BGD: 학습 한번에 모든 데이터 셋을 이용해 기울기를 업데이트\n",
    "- SGD: 학습 한번에 1개의 데이터를 이용해 기울기를 업데이트  \n",
    "- MGD: 학습 한번에 데이터 셋의 일부만 사용해 기울기 업데이트 \n",
    "<br>\n",
    "- batch_size에 따른 경사하강법의 종류를 적어주세요  \n",
    "- batch_size=1 -> SGD \n",
    "- batch_size=k -> MGD\n",
    "- batch_size=whole -> BGD  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ZGbnVHbbLMa9"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, \n",
    "                     tolerance = 0.00001, model = 'logistic', batch_size = 16):\n",
    "    stopper = False\n",
    "    \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.random.rand(N)\n",
    "    loss_function = minus_log_cross_entropy_i if model == 'logistic' else mse_i\n",
    "    loss = 999\n",
    "    batch_idx_list = batch_idx(X_train, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        if stopper:\n",
    "            break\n",
    "        for idx in batch_idx_list:\n",
    "            X_batch = X_train.iloc[idx,]\n",
    "            y_batch = y_train.iloc[idx]\n",
    "            gradients = batch_gradient(X_batch, y_batch, parameters, model)\n",
    "            parameters = step(parameters, gradients, learning_rate, len(X_batch))\n",
    "            new_loss = batch_loss(X_batch, y_batch, parameters, loss_function, len(X_batch))\n",
    "            \n",
    "            \n",
    "            #중단 조건\n",
    "            if abs(new_loss - loss) < tolerance:\n",
    "                stopper = True\n",
    "                break\n",
    "      \n",
    "            loss = new_loss\n",
    "            \n",
    "        #100epoch마다 학습 상태 출력\n",
    "        if epoch%100 == 0: #출력이 길게 나오면 check point를 수정해도 됩니다.\n",
    "            print(f\"epoch: {epoch}  loss: {new_loss}  params: {parameters}  gradients: {gradients}\")\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CTtc3eiLMa9"
   },
   "source": [
    "## Implement\n",
    "경사하강법 함수를 이용해 최적의 모수 찾아보세요. 학습을 진행할 때, Hyper Parameter를 바꿔가면서 학습시켜보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUpYC7_LMa9"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-LS6o3aeLMa-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: -1.1215414790029137  params: [0.38341275 0.2229233  0.57414167]  gradients: [0.05917831760875955, 0.053608349604660016, 0.06948316032208575]\n",
      "epoch: 100  loss: -0.07605223220430211  params: [-1.5531853   3.04421657 -2.99307075]  gradients: [0.007432015075287283, 0.010930891802396696, 0.014587087024519227]\n",
      "epoch: 200  loss: -0.07401991996827935  params: [-1.77048919  3.73649008 -3.6468187 ]  gradients: [0.0069763730041508985, 0.010566405216881018, 0.013087393517463393]\n",
      "epoch: 300  loss: -0.07352816269659793  params: [-1.86678352  4.03778659 -3.92882529]  gradients: [0.006856820864346068, 0.01044633497450161, 0.012561482036683428]\n",
      "epoch: 400  loss: -0.073344639122005  params: [-1.91539051  4.18900274 -4.06980968]  gradients: [0.006810070385417025, 0.010393181657271908, 0.012321973448323899]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.92434901,  4.22967564, -4.0845647 ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_bgd = gradient_descent(X_train, y_train)\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0oCaZ0tLMa-"
   },
   "source": [
    "### Predict Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "syJE3oiNLMa-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_bgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)\n",
    "y_predict_random = []\n",
    "for i in range(len(y_test)):\n",
    "    p= logistic(X_test.iloc[i,:], random_parameters)\n",
    "    if p> 0.5 :\n",
    "        y_predict_random.append(1)\n",
    "    else :\n",
    "        y_predict_random.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZKpFItfLMa-"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "W4E1PgX5LMa-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-veTwxu4LMa-",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  2],\n",
       "       [ 1,  9]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "h4_dW9rDLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIgqa85aLMa_"
   },
   "source": [
    "## Linear regression\n",
    "### $y = 0.5 + 2.7x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYeIg9QNLMa_"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nv8-yhszLMa_"
   },
   "outputs": [],
   "source": [
    "raw_X = np.random.rand(150)\n",
    "y = 2.7*raw_X + 0.5 + np.random.randn(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "07XtxLGWLMa_"
   },
   "outputs": [],
   "source": [
    "tmp = np.array([1 for _ in range(150)])\n",
    "X = np.vstack((tmp, raw_X)).T\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oENC02TLMa_"
   },
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "fu578YrKLMa_",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71848196, 2.37862128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규방정식\n",
    "theta = np.linalg.inv(np.dot(X.T,X)).dot(X.T).dot(y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "M74iqj4WLMa_",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.92102371446855  params: [1.38963239 0.72506705]  gradients: [-0.08247709272575865, -0.07112947130784683]\n",
      "epoch: 100  loss: 0.510953154498806  params: [0.72294196 2.45743262]  gradients: [-0.03108183844021062, -0.025011156478234514]\n",
      "epoch: 200  loss: 0.5107664886854479  params: [0.72132875 2.46023777]  gradients: [-0.0310607158714948, -0.024976210376773895]\n",
      "epoch: 300  loss: 0.5107661603949348  params: [0.7213259  2.46024271]  gradients: [-0.031060678660692537, -0.02497614881359526]\n",
      "epoch: 400  loss: 0.5107661598166001  params: [0.7213259  2.46024272]  gradients: [-0.03106067859513977, -0.024976148705141872]\n",
      "epoch: 500  loss: 0.5107661598155812  params: [0.7213259  2.46024272]  gradients: [-0.031060678595024243, -0.024976148704950758]\n",
      "epoch: 600  loss: 0.5107661598155796  params: [0.7213259  2.46024272]  gradients: [-0.031060678595024104, -0.024976148704950515]\n",
      "epoch: 700  loss: 0.5107661598155796  params: [0.7213259  2.46024272]  gradients: [-0.031060678595024104, -0.024976148704950515]\n",
      "epoch: 800  loss: 0.5107661598155796  params: [0.7213259  2.46024272]  gradients: [-0.031060678595024104, -0.024976148704950515]\n",
      "epoch: 900  loss: 0.5107661598155796  params: [0.7213259  2.46024272]  gradients: [-0.031060678595024104, -0.024976148704950515]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.7213259 , 2.46024272])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#경사하강법\n",
    "new_param = gradient_descent(X,y, model = \"linear\")\n",
    "new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Ii3zBOwSLMa_"
   },
   "outputs": [],
   "source": [
    "y_hat_NE = theta.dot(X.T)\n",
    "y_hat_GD = new_param.dot(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVynFSPLMbA"
   },
   "source": [
    "### Visualization\n",
    "시각화를 통해 정규방정식과 경사하강법을 통한 선형회귀를 비교해보세요  \n",
    "(밑의 코드를 실행만 시키면 됩니다. 추가 코드 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UoEACrbYLMbA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X.iloc[:,1], y, '.k') #산점도\n",
    "plt.plot(X.iloc[:,1], y_hat_NE, '-b', label = 'NE') #정규방정식\n",
    "plt.plot(X.iloc[:,1], y_hat_GD, '-r', label = 'GD') #경사하강법\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "wk3_optimization_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
